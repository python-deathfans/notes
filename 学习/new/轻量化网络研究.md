`GoogleNet`相比于单纯的堆叠卷积层，增加了网络宽度，降低了计算复杂度，极大提升了速度

`SqueezeNet`在保持精度的同时大大减少参数量和计算量

`MobileNetV1`使用`深度可分离卷积模块`构建轻量化模型取得了不错的结果

`MobileNetV2`在V1的基础上，借鉴了ResNet的残差结构，提出基于`反向残差的线性瓶颈结构`

`ShuffleNetV1`使用`分组卷积`和`通道混洗`的方法减少了参数量

网络都有一个共同的特点：都是由`基本构建模块堆叠而成`

| 网络       | 公开时间 | 发表情况  | arxiv链接                        |
| ---------- | -------- | --------- | -------------------------------- |
| SqueezeNet | 2016.02  | ICLR-2017 | https://arxiv.org/abs/1602.07360 |
| MobileNet  | 2016.04  | CVPR-2017 | https://arxiv.org/abs/1704.04861 |
| ShuffleNet | 2016.06  | N/A       | https://arxiv.org/abs/1707.01083 |
| Xception   | 2016.10  | CVPR-2017 | https://arxiv.org/abs/1610.02357 |

四种轻量化模型仅是在`卷积方式`上提出创新



## SqueezeNet

这篇是`ICLR 2017`（2016年上传到arxiv）的文章.主要针对`模型压缩`的.使用的是分类网络中的`AlexNet`为代表.
目前很多方法都是`只关注精度`的，但是在同等精度的情况下，小的模型很多优点，比如：

+ 训练等更快
+ 在部署时更少的带宽要求，例如自动驾驶汽车
+ 可以部署到FPGA等.

正是由于有这些优点，本文提出了一种小的CNN架构，SqueezeNet`.实现了AlexNet模型参数减少了50倍.`在受用模型压缩技术情况下，可以做到减少510倍参数，只有`0.5MB`的模型大小.

+ `使用策略`
  + 使用`1x1卷积核`替换一定数量的`3x3卷积核`
  + 减少3x3卷积核的输入特征通道数，通过在3x3卷积核之前加一层`1x1卷积核`来对输入通道数进行`降维`
  + 采用`延迟下采样`等方式保证模型的分类准确率

网络基本模型是`Fire module`。

包括两部分，`Squeeze`层和`Expand`层

![](https://pic.downk.cc/item/5f588bc5160a154a67effe86.png)

+ 三个可调参数
  + S1
  + e1
  + e3
+ SqueezeNet中,`e1=e3=4S1`
+ 网络结构
  + ![](https://pic.downk.cc/item/5f588c5c160a154a67f08318.png)

## MobileNet V1

MobileNet是`Google`公司于`2017`年面向移动端而提出的一种轻量级卷积神经网络.

整体结构类似于`VGG16`,堆叠多层卷积层，最后连接一个`全连接层`和一个`softmax分类器`。

+ 核心构建模块是一个`深度可分离卷积`
  + `深度卷积`
    + 通道卷积
  + `逐点卷积`
    + 1x1卷积
+ 两个超参数：`宽度因子`和`分辨率因子`

包含`大量的1x1卷积层`，所以这部分占据了很多部分。

![](https://pic.downk.cc/item/5f55d37e160a154a674d17dc.png)

## MobileNet V2

+ 引入`线性瓶颈结构`
  + 去掉低维度输出层后面的非线性激活层，目的是保证模型的表达能力
  + 瓶颈层的`输出不接非线性激活层`

+ `反向残差结构`

## ShuffleNet

ShuffleNet是由Face++团队提出的轻量级网络模型，该模型的设计采纳了`ResNet`,`MobileNet`等网络模型的核心思想，主要组成单元源自于ResNet的`残差模块`，具体结构如图2-8所示。相比于原始的ResNet残差结构，ShuffleNet通过采用`分组卷积`以及`通道混洗`策略进行改进，在ShuffleNet基本单元模块中，将第一个1×1卷积替换为分组卷积，之后接一个`通道混洗层`，该层用于`打乱将上一层的特征通道顺序`，接着便是MobileNet中的`深度可分离卷积层`。ShuffleNet模型最主要的创新在于通道混洗，该工作作者在采用`分组卷积方法减少模型的参数量`以及计算量的时候发现，分组卷积会导致信息隔离，各组的特征通道信息无法与其他组的特征通道信息融合，最终影响模型性能，为了解决这个问题，ShuffleNet提出了`通道混洗的方法，对分组卷积得到的输出数据打乱特征顺序，交叉各组之间的信息，提高模型的表征能力。`

![](https://pic.downk.cc/item/5f55d46a160a154a674d4827.png)

## 轻量化技巧

+ `SqueezeNet`
  + 1x1替代3x3卷积，参数量减少
  + 减少3x3卷积输入通道数，减少参数量
  + `Fire module`
  + `降采样操作延后`，给卷积层提供更大激活图，提高分类准确度
+ `SqueezeNext`
  + 两级Squeeze层压缩特征图通道数
  + 低秩的可分离卷积减少参数量
  + 减少全连接层的输入通道数，降低计算复杂度和减少参数量
+ `MobileNet V1`
  + `深度可分离卷积`降低计算复杂度，减少参数量
  + `两个超参数`降低计算复杂度，减少参数量
+ `MobileNet V2`
  + 利用`反向残差`结构降低了1x1卷积的占比
  + `线性瓶颈结构`避免通道压缩后的信息被破坏，以保证准确度
  + `两个超参数`降低计算复杂度，减少参数量
+ `ShuffleNet V1`
  + 1x1`分组卷积`降低计算复杂度和减少参数量
  + `通道混洗`解决分组间信息不流畅

`分组卷积`在轻量化设计中非常重要，深度卷积是分组卷积的特殊形式，可以有效降低计算复杂度，减少参数量。但是使用分组卷积会出现组间“信息流通不畅”问题，影响模型的表达能力。解决办法是通道混洗或者点卷积。

使用`1x1卷积`压缩特征通道也是一个重要的技巧。

另外`残差单元`也是一个非常重要的结构。残差网络使得信息更容易在各层之间流动，包括在前向传播或者反向传播中。可以解决梯度消失

### 分组卷积

> 顾名思义，是对输入特征图按照`通道数进行分组`，然后每组进行卷积。

**![](https://pic.downk.cc/item/5f55d729160a154a674de4a9.png)**

![](https://pic.downk.cc/item/5f55d758160a154a674deea9.png)

### 通道混洗

ShuffleNet的核心设计思想是将`各个组的特征通道进行重新洗牌，打乱顺序`，来解决分组卷积带来的`组件信息不流通`的问题。分组卷积运算会先将所有的特征通道分为若干组，然后每一个组内各自进行卷积操作，提取各自组里的抽象特征。普通的卷积操作是在所有的特征通道上进行卷积，即`全通道卷积`，这是一种特征通道密集连接方式，而分组卷积相比较来讲是一种`通道稀疏`的连接方式。

现在的卷积神经网络模型通常由具有`相同结构的卷积层基本模块`重复构建而成，其中比较先进的网络，如Xception、MobileNet和ResNetX,都将深度可分离卷积或者分组卷积引入基本的卷积层构建模块中，在模型的性能和计算成本之间取得了良好的平衡。然而也可以注意到这两种设计中的1×1逐点卷积层占用了较大比例的计算量，逐点卷积层在所有的特征通道上进行卷积计算，是一种密集通道连接方式。

### bottleneck layer 瓶颈层

又称为瓶颈层，使用的是1x1卷积神经网络。之所以称为瓶颈层，是因为长的像一个瓶颈。

![](https://pic.downk.cc/item/5f5ac722160a154a6722f2d0.png)

如上图所示，经过1x1的网络，中间那个看起来比较细。像一个瓶颈一样。使用1x1网络的一大好处就是可以`大幅减少计算量`