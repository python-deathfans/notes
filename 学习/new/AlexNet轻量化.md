## AlexNet

+ 主要表现
  + 使用`数据增强`的方式对图像数据进行预处理增大了训练的数据量，一定程度提高了算法的准确率
  + 使用`LRN局部响应归一化`对图像的每个像素进行调整，使得图像的主体部分能够和背景更加具有区分度。
  + 用`Relu`代替了sigmoid,加快了网络的收敛，有效防止了梯度弥散现象。
  + 全连接层后面使用了`Dropout`技术，极大避免过拟合现象。

## 轻量化

> `传统的卷积神经网络`，网络结构由卷积层和池化层相互组合堆叠而成，且每层卷积层都`只采用单一尺寸`的卷积核进行特征提取。事实上，同一层feature map可以分别使用`多个不同尺寸的卷积核`，以获得不同尺度的特征，再把这些特征组合起来，得到的特征往往比单一卷积核的要好，例如Inception结构，就使用了多个卷积核的结构。

![](https://pic.downk.cc/item/5f59be90160a154a679d4520.jpg)

+ 两种卷积方式
+ 第二种，先压缩，然后卷积

![](https://pic.downk.cc/item/5f59bf1c160a154a679d66c9.png)

+ 模块使用`三组卷积核`对输入图像进行卷积提取特征
+ 三组卷积提取特征后，将提取的特征图像级联起来，作为下一层的输入特征

![](https://pic.downk.cc/item/5f59c615160a154a679ffa32.png)

### 数据增强

+ **归一化处理**

+ 左上角、右上角、左下角、右下角**随机裁剪图片**，进行**水平翻转**

  