> `方法`
>
> + CNN+LBP特征
>
> + HOG 3D
>
> + Cov3D
>
> + Faceness-Net
>
> + Inception
>
> + IACNN
>
> + DTAGN



> `步骤`
>
> + **人脸检测**
>   + **找出图像中人脸的位置**
>   + 传统方法
>     + 基于外观
>     + 基于知识
>     + 基于模板
>     + 基于特征
>       + **LBP**
>       + **Gabor小波**
>   + 深度学习方法
>     + `R-CNN`
>       + 需要预先进行图像后溴铵区域的进行提取，无法实现端到端的简洁模型
>       + CNN提取的特征需要写入到磁盘，占据额外的存储
>       + 使用SVM进行分类，没有使用CNN进行分类
>     + `Fast RCNN`
>       + 将特征提取和分类直接由一个卷积神经网络完成，避免将特征向量存储进磁盘，减小了对于磁盘的消耗
>     + `Faster RCNN`
>       + 由于可以端到端的学习，可以在模型训练期间使得模型充分优化，进而提升模型的检测准确
>       + 何凯明   SPP-NET
>         + 对于输入图片大小没有要求
>         + 全连接层之前增加`空间金字塔池化层`
>     + `FacenessNet`
>     + 模板匹配方法
>     + Viola-Jones算法
>       + Adaboost结合Haar特征
>     + 基于**深度学习**的人脸检测方法
>       + Cascade CNN是对于V-J模型的一个改进
> + **人脸表情特征提取**
>   + 静态传统方法
>     + `LBP特征`
>     + Haar特征
>     + `PCA`
>     + `Gabor小波`
>   + 动态传统方法
>     + 光流法
> 
>    + ASM
>     + AAM
> 
>    + 模型法
>     + 几何法
>     + LSTM
>     + 3D CONV
>     + 双流法
> + **人脸表情识别**
>   + 贝叶斯分类法
>   + SVM
>   + 基于CNN的分类算法
>     + RCNN
>     + FASTER RCNN
>   + Adaboost算法
>   + PCA

> 人脸表情识别技术，其应用场景较为广泛，主要应用在以下的几个`现实场景`：
> (1)在`人机交互领域`，人脸表情识别可以提高"聊天机器人"的智能。和老人聊天的时候，可以捕捉老人心情和感情的变化。和小孩沟通的时候，需要捕捉小孩的心情和感情的变化。
> (2)在`安全驾驶领域`，利用面部表情识别技术能够时时刻刻监护司机面部表情状态，从而判断司机是否是疲劳驾驶，若是疲劳驾驶，可以自动报警，对司机起一个监督作用，减少交通事故的发生。
> (3)在`智能监护领域`，`医疗方面`，利用能够面部表情识别的机器人，通过辨别患者疼痛的表情等异常，可以做出报警。
> (4)在`案件侦测`方面，在审查嫌疑人时，根据犯罪嫌疑人的面部表情变化，机器自动识别并学习其复杂的心理变化，从而揣摩对方的行为动机，为警察破案提供一定的帮助。
>
> (5)商品智能推荐在`智能推荐领域`，商品推荐系统可以参考人们在浏览各类商品时的表情进行分析并进而判断其喜爱程度，将喜爱程度值加入推荐系统以便向消费者推荐更受欢迎的商品。
>
> (6)`远程教育系统` 在远程教育领域，系统可以检测学生上课时的面部表情反馈信息，判断学生掌握知识的情况，也可实时结合只能算法根据学生和老师的沟通情况给出良好的授课建议

> `难点`
>
> + 在自然环境中，`人体头部的角度和姿态差异巨大`，脸部往往会发生形变，给检测带来困难
>   + 人脸对齐的关键是**人脸关键点的定位**，通过关键点归一化到统一的标准
>   + 方法
>     + 基于线性回归
>     + 基于非线性回归
> + 不同的`光照`下、过明或者过暗都会导致识别错误。还有`遮挡物`，也会对于识别造成困难
> + 同一类表情在`不同年龄、性别、种族`的人群中表现形式往往不同，这就很难建立一个统一的人脸表情识别模型进行识别
> + `数据的匮乏`，人脸表情的采集具有一定的困难，需要在一定的环境采集带有标签的数据
>   + 数据太少，容易过拟合
>   + 不能使用层数太深的网络进行训练

> `网络训练策略`
>
> + 先让模型在`FER-2013`模型进行预训练，目的是让模型有初步的`提取能力`。使用`Early Stoping`的方式进行训练迭代终止。
> + 然后采用隔离损失的网络模型在`CK+`数据集上进行微调训练，得到最终的网络模型

## 人脸检测

> 问题描述：
>
> 人脸检测目标是找出图像中所有的人脸对应的位置，算法的输出是人脸外接矩阵在图像汇总的坐标，可能还包括姿态和倾斜角度等信息。
>
> 核心问题：
>
>  人脸可能出现在图像中的**任何一个位置**
>  人脸可能有**不同的大小**
>  人脸在图像中可能有**不同的视角和姿态**
>  人脸可能部分被**遮挡**
>
> ![](https://pic.downk.cc/item/5f0e5a9a14195aa59412a020.png)
>
> ![](https://pic.downk.cc/item/5f0e5abd14195aa59412a7e1.png)

### 经典做法

+ 用大量的人脸和非人脸样本图像进行训练，得到一个解决`2类分类问题的分类器`，也称为人脸检测模板。这个分类器接受`固定大小的输入图片`，判断这个输入图片`是否为人脸`，即解决是和否的问题。
+ 由于人脸可能出现在图像的`任何位置`，在检测时用固定大小的窗口对图像`从上到下、从左到右扫描`，判断窗口里的子图像是否为人脸，这称为`滑动窗口技术`（sliding window）。为了检测`不同大小的人脸`，还需要对图像进行放大或者缩小构造图像金字塔，对每张缩放后的图像都用上面的方法进行扫描。由于采用了滑动窗口扫描技术，并且要对图像进行反复缩放然后扫描，因此整个检测过程会非常耗时。
+ 由于一个人脸附件可能会检测出`多个候选位置框`，还需要将检测结果进行`合并去重`，这称为非极大值抑制（`NMS`）

### 早期算法

+ 早期的人脸检测算法使用了`模板匹配技术`，即用一个人脸模板图像与被检测图像中的`各个位置`进行匹配，确定这个位置处是否有人脸；此后机器学习算法被用于该问题，包括神经网络，支持向量机等。以上都是针对图像中某个区域进行人脸-非人脸二分类的判别。

### Adaboost框架

+ 在2001年`Viola和Jones`设计了一种人脸检测算法。它使用简单的`Haar-like`特征和级联的`AdaBoost`分类器构造检测器，检测速度较之前的方法有2个数量级的提高，并且保持了很好的精度，我们称这种方法为`VJ框架`。VJ框架是人脸检测历史上第一个最具有里程碑意义的一个成果，奠定了基于AdaBoost目标检测框架的基础

### 深度学习

+ `Cascade CNN`
  + 可以认为是`传统技术和深度网络`相结合的一个代表，和VJ人脸检测器一样，其包含了多个分类器，这些分类器采用级联结构进行组织，然而不同的地方在于，Cascade CNN采用卷积网络作为每一级的分类器。
+ `DenseBox`
  + 适合人脸这类小目标的检测。这种方法使用`全卷积网络`，在同一个网络中直接预测目标矩形框和目标类别置信度。通过在检测的同时进行关键点定位，进一步提高了检测精度。
+ `Faceness-Net`
  + 是一个典型的`由粗到精`的工作流，借助了多个基于DCNN网络的facial parts分类器对人脸进行打分，然后根据每个部件的得分进行规则分析得到Proposal的人脸区域，最后通过一个Refine的网络得到最终的人脸检测结果。
+ `MTCNN`
  + 顾名思义是`多任务`的一个方法，它将`人脸区域检测`和`人脸关键点检测`放在了一起，同Cascade CNN一样也是基于cascade的框架，但是整体思路更加巧妙合理，MTCNN总体来说分为三个部分：PNet、RNet和ONet，如下图所示：
  + ![](https://pic.downk.cc/item/5f0ea0a614195aa594287a3c.jpg)

+ `Face R-CNN`
  + 该方法基于`Faster R-CNN`框架做人脸检测，针对人脸检测的特殊性做了优化。
  + 对于最后的二分类，在softmax的基础上增加了center loss。通过加入center loss使得类内的特征差异更小（起到聚类的作用），提高正负样本在特征空间的差异性从而提升分类器的性能。