> 一般来说，`提升网络性能`最直接的办法就是`增加网络深度和宽度`，`深度指网络层次数量`、`宽度指神经元数量`。但这种方式存在以下问题：
> （1）`参数太多`，如果`训练数据集有限，很容易产生过拟合`；
> （2）`网络越大、参数越多，计算复杂度越大，难以应用`；
> （3）`网络越深，容易出现梯度弥散问题（梯度越往后穿越容易消失），难以优化模型`

## Inception V1

![](https://pic.downk.cc/item/5f7ef79d1cd1bbb86bbe86e8.png)

该结构将CNN中常用的卷积（1x1，3x3，5x5）、池化操作（3x3）堆叠在一起（`卷积、池化后的尺寸相同，将通道相加`），一方面增加了网络的宽度，另一方面也增加了网络对尺度的适应性.

GoogLeNet特点

+ 采用了`模块化(Inception结构)`，方便增添和修改
+ 采用`平均池化代替了全连接层`，该想法来自`NIN`，事实证明这样可以将准确率提高0.6%

## Inception V2

![](https://pic.downk.cc/item/5f7efb821cd1bbb86bbfa4b1.png)

创新

+ `卷积分解`
  + 用2个连续的3x3卷积层组成的小网络来代替单个的5x5卷积层，即在保持感受野范围的同时又减少了参数量
  + `大卷积核完全可以由一系列的3x3卷积核来替代`，那能不能再分解得更小一点呢？GoogLeNet团队考虑了`nx1的卷积核`,用`3个3x1取代3x3卷积`
  + `任意nxn的卷积都可以通过1xn卷积后接nx1卷积来替代`

## Inception V3

+ 卷积分解
+ 输入维度变化

## Inception V4

+ 结合`残差网络`





