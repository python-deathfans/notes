> 国外开始研究的比较早，国内是1997年，哈尔滨工业大学首次引入进行研究。

# 一、应用场景

人脸表情识别技术，其应用场景较为广泛，主要应用在以下的几个`现实场景`：

+ 在`人机交互领域`，人脸表情识别可以提高"聊天机器人"的智能。和老人聊天的时候，可以捕捉老人心情和感情的变化。和小孩沟通的时候，需要捕捉小孩的心情和感情的变化。
+ 在`安全驾驶领域`，利用面部表情识别技术能够时时刻刻监护司机面部表情状态，从而判断司机是否是疲劳驾驶，若是疲劳驾驶，可以自动报警，对司机起一个监督作用，减少交通事故的发生。
+ 在`智能监护领域`，`医疗方面`，利用能够面部表情识别的机器人，通过辨别患者疼痛的表情等异常，可以做出报警
+ 在`案件侦测`方面，在审查嫌疑人时，根据犯罪嫌疑人的面部表情变化，机器自动识别并学习其复杂的心理变化，从而揣摩对方的行为动机，为警察破案提供一定的帮助。
+ 商品智能推荐在`智能推荐领域`，商品推荐系统可以参考人们在浏览各类商品时的表情进行分析并进而判断其喜爱程度，将喜爱程度值加入推荐系统以便向消费者推荐更受欢迎的商品。
+ `远程教育系统` 在远程教育领域，系统可以检测学生上课时的面部表情反馈信息，判断学生掌握知识的情况，也可实时结合只能算法根据学生和老师的沟通情况给出良好的授课建议

# 二、现存问题

+ 在自然环境中，`人体头部的角度和姿态差异巨大`，脸部往往会发生形变，给检测带来困难
+ 数据太少，容易过拟合
+ 同一类表情在`不同年龄、性别、种族`的人群中表现形式往往不同，这就很难建立一个统一的人脸表情识别模型进行识别`数据的匮乏`，人脸表情的采集具有一定的困难，需要在一定的环境采集带有标签的数据
+ 不同的`光照`下、过明或者过暗都会导致识别错误。还有`遮挡物`，也会对于识别造成困难

# 三、静态图片

> 仅考虑当前的状态，只对当前的状态进行编码



## 3.1 预处理(人脸检测)

> 与面部表情无关的变化，比如不同的背景，光照和头部姿势，在无限制的场景中非常常见。因此训练之前，预处理通常是人脸对齐、规范化处理。

人脸表情的变化，从细节上看带动的是面部肌肉以及纹理的细微变化，从`整体`上看，会影响人脸图像的整体信息，所以从整体角度考虑人脸表情特征，这就是`整体法`，如果从`局部的纹理角度`考虑人脸表情特征，这就是`局部法`。

`整体法`

+ PCA
+ ICA

`局部法`

+ Garbor小波
  + 对于`光照有较好的适应性`
  + 对边缘信息比较敏感
+ LBP
  + 对于光照也有很强的敏感性



### 3.1.1 人脸对齐

给定一系列训练数据，第一步是`检测人脸`，然后`去除背景和非人脸区域`

`V-J检测器`是一个非常经典的人脸检测器。

虽然人脸检测是必不可少的一个步骤，但是使用`局部坐标`可以进一步的显著提高FER性能。

`经常使用的带有面部地标的模型`：

![](https://pic.downk.cc/item/5f138b1e14195aa594aba5c3.png)

### 3.1.2 数据增强

+ 动态
  + 嵌入到深度学习工具中，防止过拟合
+ 离线

### 3.1.3 人脸归一化

+ 光照归一化
  + 直方图均衡化
+ 姿态归一化

## 3.2 特征提取

## 3.3 表情识别

+ 传统的特征提取和分类是分开的，深度学习可以实现`端到端`的方法
+ 两种方法
  + 要么是`softmax`进行分类
  + 要么外接分类器，可以是`SVM`或者`随机森林`

## 3.4 网络融合

+ 网络的`足够多样性`确保互补性

## 3.5 Multitask networks

## 3.6 Cascaded Networks

## 3.7 GANS



# 四、动态图片

> 考虑输入序列中相邻帧之间的时间关系

# 五、讨论

> 现有两个关键问题
>
> + 缺乏丰富的数据
> + 光照、头部姿势的影响



# 六、额外问题

## 6.1 遮挡和没有正面头部姿势

# 七、挑战和未来方向

## 7.1 面部表情数据集

deep-FER系统面临的问题是训练数据在`数量和质量`上的缺乏。

缺乏足够的面部表情数据集，包括`遮挡类型和头部姿势注释`

## 7.2 数据集偏差与不平衡分布

由于`不同的采集条件`和`标注的主观性`，在不同的人脸表情数据集中，数据偏差和标注不一致现象非常普遍。

# 深度学习

+ `Cascade CNN`
  + 是对V-J检测模型的一个改进，也是使用多个分类器进行级联
  + 模型是用卷积网络作为每一级的分类器，Cascade CNN 的网络级联是`三阶`的，分别是 `12-net、24-net 和 48-net`
+ `R-CNN`
  + 需要预先进行图像后溴铵区域的进行提取，无法实现端到端的简洁模型
  + CNN提取的特征需要写入到磁盘，占据额外的存储
  + 使用SVM进行分类，没有使用CNN进行分类
+ `Fast RCNN`
  + 将特征提取和分类直接由一个卷积神经网络完成，避免将特征向量存储进磁盘，减小了对于磁盘的消耗
+ `Faster RCNN`
  + 由于可以端到端的学习，可以在模型训练期间使得模型充分优化，进而提升模型的检测准确
  + 何凯明   SPP-NET
    + 对于输入图片大小没有要求
    + 全连接层之前增加`空间金字塔池化层`
+ `Faceness-Net`
  + 基于DCNN网络的一个人脸特征检测器，首先利用网络检测`人脸局部特征`，包括头发、眼睛、鼻子、嘴巴和胡子等特征，并生成`人脸局部图`，推理出`人脸候选区域`，此时的候选区域可以达到很好的召回率，但是和候选区匹配的图像并不一定就能判别为人脸，所以，还要训练一个多任务的卷积网络来完成人脸分类和矩形框坐标回归，从而进一步增强该网络检测人脸的效果。

+ `Cascade CNN`
  + 可以认为是`传统技术和深度网络`相结合的一个代表，和VJ人脸检测器一样，其包含了多个分类器，这些分类器采用级联结构进行组织，然而不同的地方在于，Cascade CNN采用卷积网络作为每一级的分类器。
+ `DenseBox`
  + 适合人脸这类小目标的检测。这种方法使用`全卷积网络`，在同一个网络中直接预测目标矩形框和目标类别置信度。通过在检测的同时进行关键点定位，进一步提高了检测精度。
+ `Faceness-Net`
  + 是一个典型的`由粗到精`的工作流，借助了多个基于DCNN网络的facial parts分类器对人脸进行打分，然后根据每个部件的得分进行规则分析得到Proposal的人脸区域，最后通过一个Refine的网络得到最终的人脸检测结果。
+ `MTCNN`
  + 顾名思义是`多任务`的一个方法，它将`人脸区域检测`和`人脸关键点检测`放在了一起，同Cascade CNN一样也是基于cascade的框架，但是整体思路更加巧妙合理，MTCNN总体来说分为三个部分：PNet、RNet和ONet，如下图所示：
  + ![](https://pic.downk.cc/item/5f0ea0a614195aa594287a3c.jpg)

+ `Face R-CNN`
  + 该方法基于`Faster R-CNN`框架做人脸检测，针对人脸检测的特殊性做了优化。
  + 对于最后的二分类，在softmax的基础上增加了center loss。通过加入center loss使得类内的特征差异更小（起到聚类的作用），提高正负样本在特征空间的差异性从而提升分类器的性能。
