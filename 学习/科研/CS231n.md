> 2017年之后imagenet比赛不在继续举行
>
> 专家认为图片分类已经完全得到了解决

## 卷积神经网络

+ **卷积层**
  + **特征提取**
  + **边缘信息丢失** 
    + 引入padding
    + 主要是zero padding
+ **池化层**
  + 下采样
  + 上采样
  + **作用**
    + 减少参数量
    + 防止过拟合
    + 引入平移不变性
+ **全连接层**
  + **特征融合**
+ **特点**
  + **局部感受野**
  + **权值共享**
  + **下采样，减少参数，防止过拟合**



## 可视化卷积神经网络

## 训练神经网络

+ **一劳永逸的配置**
  + **激活函数**
    + ![](https://pic.downk.cc/item/5e92c1b6c2a9a83be5132bf9.png)
  + **数据预处理**
    + **标准化**
    + **主成分分析**
      + PCA
      + ZCA
  + 权重初始化
    + 标准正态分布
  + 正则化
    + batch normalization(BN层)
      + 一般放在**非线性层之前**
      + 加快收敛
      + 改善梯度
  + 梯度下降算法
    + SGD
    + SGD+Momentum
    + AdaGrad
    + RMSProp
    + Adam
+ **训练中关注**
  + 超参数
    + 检测初始损失函数
    + 在小数据集是否过拟合
    + 找到快速下降的学习率
    + 学习率先大后小
    + 注意损失函数的可视化图像
  + 参数更新 
  + 学习率
    + 前期**大学习率**，后期**小学习率**
+ **模型评估与集成**
  + checkpoint
  + 好而不同
  + 正则化
    + dropout
  + 数据增强

## 卷积神经网络工程实践技巧

+ 3x3 + 3x3 == 5x5	filter size

+ 3x3 + 3x3 + 3x3 == 7x7

  + **多个小卷积核代替一个大卷积核**

+ **迁移学习**

  + 打破了一个魔咒，你需要**许多的数据**去训练一个网络
  + **数据集较小**
    + fine tuning
    + 只训练最后一层
    + 冻结前面的层
  + **数据集较大**
    + 训练最后的全连接层
    + 冻结前面的层
  + ![](https://pic.downk.cc/item/5e940c07c2a9a83be5cadfe9.png)

  + ![](https://pic.downk.cc/item/5e940ce8c2a9a83be5cb5cff.png)

+ ![](https://pic.downk.cc/item/5e940dfac2a9a83be5cbfdfc.png "细节处理")



## 经典网络结构分析

+ ![](https://pic.downk.cc/item/5e9410c2c2a9a83be5cdabfc.png)
+ ![](https://pic.downk.cc/item/5e92b513c2a9a83be50ae220.png)
+ ![](https://pic.downk.cc/item/5e941172c2a9a83be5ce095c.png)
+ ![](https://pic.downk.cc/item/5e9416a0c2a9a83be5d0c37a.png "VGG16")
+ ![](https://pic.downk.cc/item/5e9416fec2a9a83be5d0f56b.png "VGG16 VS VGG19")
+ 1x1卷积作用**
  + 降维或者升维
  + 跨通道信息交流
  + **减少参数量**
  + 增加模型深度 
  + **提高非线性能力**